set.seed(99)
trainIndex <- createDataPartition(data$Cost_of_Bike, p = .7, list = FALSE)
training <- data[trainIndex, ]
testing <- data[-trainIndex, ]
# Define linear regression model
model <- lm(Cost_of_Bike ~ longitude + latitude, data = training)
summary(model)
ggplot(summary_table, aes(x = Year, y = Theft_Count)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen")
# Perform cross-validation
set.seed(99)
cv <- train(Cost_of_Bike ~ longitude + latitude, data = training, method = "lm", trControl = trainControl(method = "cv", number = 5))
# Print cross-validation results
print(cv)
# Predict the test set using the cross-validated model
predictions <- predict(cv, newdata = testing)
# Evaluate performance using metrics such as mean squared error, mean absolute error, and R-squared value
mse <- mean((predictions - testing$Cost_of_Bike) ^ 2)
mae <- mean(abs(predictions - testing$Cost_of_Bike))
r_squared <- cor(predictions, testing$Cost_of_Bike) ^ 2
library(tidyr)
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(123)
trainIndex <- createDataPartition(data$Theft_Count, p = .8, list = FALSE)
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(123)
trainIndex <- createDataPartition(data$Theft_Count, p = .8, list = FALSE)
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(123)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trControl = ctrl)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen") +
geom_smooth(aes(y = predict(lmFit, training)),
method = "lm", se = FALSE, color = "blue") +
geom_smooth(aes(y = predict(lmFit, testing)),
method = "lm", se = FALSE, color = "green")
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(123)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trainControl = ctrl)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen") +
geom_smooth(aes(y = predict(lmFit, training)),
method = "lm", se = FALSE, color = "blue") +
geom_smooth(aes(y = predict(lmFit, testing)),
method = "lm", se = FALSE, color = "green")
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(123)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trainControl = ctrl)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen")
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(123)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trainControl = ctrl)
# Fit a linear regression model to the training data
lm_model <- lm(Theft_Count ~ Year, data = training)
# Print the summary of the model
summary(lm_model)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen") +
geom_smooth(aes(y = predict(lmFit, training)),
method = "lm", se = FALSE, color = "blue") +
geom_smooth(aes(y = predict(lmFit, testing)),
method = "lm", se = FALSE, color = "green")
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(123)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trainControl = ctrl)
# Fit a linear regression model to the training data
lm_model <- lm(Theft_Count ~ Year, data = training)
# Print the summary of the model
summary(lm_model)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen")
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(123)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trainControl = ctrl)
# Fit a linear regression model to the training data
lm_model <- lm(Theft_Count ~ Year, data = training)
# Print the summary of the model
summary(lm_model)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen")
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(99)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit a linear regression model to the training data
lm_model <- lm(Theft_Count ~ Year, data = training)
# Print the summary of the model
summary(lm_model)
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trainControl = ctrl)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen")
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(99)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit a linear regression model to the training data
lm_model <- lm(Theft_Count ~ Year, data = training)
# Print the summary of the model
summary(lm_model)
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trControl = ctrl)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen")
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(99)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit a linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lm_model <- train(Theft_Count ~ Year, data = training, method = "lm",
trControl = ctrl)
# Print the summary of the model
summary(lm_model)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen") +
geom_smooth(aes(y = predict(lm_model, training)),
method = "lm", se = FALSE, color = "blue") +
geom_smooth(aes(y = predict(lm_model, testing)),
method = "lm", se = FALSE, color = "green")
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(99)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit a linear regression model to the training data
lm_model <- lm(Theft_Count ~ Year, data = training)
# Print the summary of the model
summary(lm_model)
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trainControl = ctrl)
# Predict values for the training and test sets
training$predicted <- predict(lm_model, newdata = training)
testing$predicted <- predict(lm_model, newdata = testing)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen") +
geom_line(aes(x = Year, y = predicted), data = training, color = "blue") +
geom_line(aes(x = Year, y = predicted), data = testing, color = "green")
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(99)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit a linear regression model to the training data
lm_model <- lm(Theft_Count ~ Year, data = training)
# Print the summary of the model
summary(lm_model)
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trControl = ctrl)
# Predict values for the training and test sets
training$predicted <- predict(lm_model, newdata = training)
testing$predicted <- predict(lm_model, newdata = testing)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen") +
geom_line(aes(x = Year, y = predicted), data = training, color = "blue") +
geom_line(aes(x = Year, y = predicted), data = testing, color = "green")
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(99)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit a linear regression model to the training data
lm_model <- lm(Theft_Count ~ Year, data = training)
# Print the summary of the model
summary(lm_model)
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trControl = ctrl)
# Predict values for the training and test sets
training$predicted <- predict(lm_model, newdata = training)
testing$predicted <- predict(lm_model, newdata = testing)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point(0.5) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen") +
geom_line(aes(x = Year, y = predicted), data = training, color = "blue") +
geom_line(aes(x = Year, y = predicted), data = testing, color = "green")
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(99)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit a linear regression model to the training data
lm_model <- lm(Theft_Count ~ Year, data = training)
# Print the summary of the model
summary(lm_model)
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trControl = ctrl)
# Predict values for the training and test sets
training$predicted <- predict(lm_model, newdata = training)
testing$predicted <- predict(lm_model, newdata = testing)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point(alpha=0.5) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen") +
geom_line(aes(x = Year, y = predicted), data = training, color = "blue") +
geom_line(aes(x = Year, y = predicted), data = testing, color = "green")
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(99)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit a linear regression model to the training data
lm_model <- lm(Theft_Count ~ Year, data = training)
# Print the summary of the model
summary(lm_model)
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trControl = ctrl)
# Predict values for the training and test sets
training$predicted <- predict(lm_model, newdata = training)
testing$predicted <- predict(lm_model, newdata = testing)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point(alpha=0.1) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen") +
geom_line(aes(x = Year, y = predicted), data = training, color = "blue") +
geom_line(aes(x = Year, y = predicted), data = testing, color = "green")
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(99)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit a linear regression model to the training data
lm_model <- lm(Theft_Count ~ Year, data = training)
# Print the summary of the model
summary(lm_model)
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trControl = ctrl)
# Predict values for the training and test sets
training$predicted <- predict(lm_model, newdata = training)
testing$predicted <- predict(lm_model, newdata = testing)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen") +
geom_line(aes(x = Year, y = predicted), data = training, color = "blue") +
geom_line(aes(x = Year, y = predicted), data = testing, color = "green")
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(99)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit a linear regression model to the training data
lm_model <- lm(Theft_Count ~ Year, data = training)
# Print the summary of the model
summary(lm_model)
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trControl = ctrl)
# Predict values for the training and test sets
training$predicted <- predict(lm_model, newdata = training)
testing$predicted <- predict(lm_model, newdata = testing)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red", alpha=0.5) +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen") +
geom_line(aes(x = Year, y = predicted), data = training, color = "blue") +
geom_line(aes(x = Year, y = predicted), data = testing, color = "green")
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(99)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit a linear regression model to the training data
lm_model <- lm(Theft_Count ~ Year, data = training)
# Print the summary of the model
summary(lm_model)
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trControl = ctrl)
# Predict values for the training and test sets
training$predicted <- predict(lm_model, newdata = training)
testing$predicted <- predict(lm_model, newdata = testing)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red", alpha=0.1) +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen") +
geom_line(aes(x = Year, y = predicted), data = training, color = "blue") +
geom_line(aes(x = Year, y = predicted), data = testing, color = "green")
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(99)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit a linear regression model to the training data
lm_model <- lm(Theft_Count ~ Year, data = training)
# Print the summary of the model
summary(lm_model)
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trControl = ctrl)
# Predict values for the training and test sets
training$predicted <- predict(lm_model, newdata = training)
testing$predicted <- predict(lm_model, newdata = testing)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red", alpha=0.1) +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen") +
geom_line(aes(x = Year, y = predicted), data = training, color = "blue") +
geom_line(aes(x = Year, y = predicted), data = testing, color = "green")
knitr::opts_chunk$set(echo = TRUE)
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(99)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit a linear regression model to the training data
lm_model <- lm(Theft_Count ~ Year, data = training)
# Print the summary of the model
summary(lm_model)
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trControl = ctrl)
# Predict values for the training and test sets
training$predicted <- predict(lm_model, newdata = training)
testing$predicted <- predict(lm_model, newdata = testing)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red", alpha=0.1) +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen") +
geom_line(aes(x = Year, y = predicted), data = training, color = "blue") +
geom_line(aes(x = Year, y = predicted), data = testing, color = "green")
knitr::opts_chunk$set(echo = TRUE)
#Linear Regression and Cross Validation part
# Split the data into training and test sets
set.seed(99)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]
# Fit a linear regression model to the training data
lm_model <- lm(Theft_Count ~ Year, data = training)
# Print the summary of the model
summary(lm_model)
# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
trControl = ctrl)
# Predict values for the training and test sets
training$predicted <- predict(lm_model, newdata = training)
testing$predicted <- predict(lm_model, newdata = testing)
# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, color = "red", alpha=0.1) +
labs(title = "Bike Theft in Toronto",
x = "Year of Bike Theft",
y = "Number of Bikes Stolen") +
geom_line(aes(x = Year, y = predicted), data = training, color = "blue") +
geom_line(aes(x = Year, y = predicted), data = testing, color = "green")
