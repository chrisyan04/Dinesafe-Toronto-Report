---
title: "Bicycle Theft Report"
subtitle: "What is the scope of bike theft in Toronto over the past few years?"
author: "Chris Yan 1009096746, Aaron Dong 1008961232, Armaan Rehman Shah 1009641309"
date: "2023-04-07"
output: html_document
---

```{r setup, include=FALSE, warnings=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}
# Importing the dataset
origin <- read.csv("bicycle.csv")
```

```{r, include=FALSE}
# Initiating libraries
library(tidyverse)
library(tidyr)
library(ggplot2)
library(ggmap)
library(png)
library(ggpubr)
library(osmdata)
library(gganimate)
library(scales)
library(dplyr)
library(stringr)
library(knitr)
library(caret)
```

## Introduction

  The report concerns with the data "Bicycle Thefts Open Data" which contains occurrences related to bicycle thefts reported to the Toronto Police Service. These occurrences are related to a variety of offences where the theft of a bicycle was included. We obtained this dataset from the City of Toronto Open Data portal. It records all of the bike thefts in Toronto starting from as early as 2013. The dataset is published by the Toronto Police services and is refreshed annually all the way up until 2022. The dataset contains large amount of entries and multiple information variables.
\

### Purpose
The purpose of our report is to inform the public about the bike safety concerns in Toronto and its surrounding areas with regards to the precedence of stolen bikes in certain areas. We want to make it known in our report that the public should avoid parking bikes in hot-spots where bikes are often stolen. A map of the density of the stolen bike occurrences will show the precise locations where one should avoid leaving their bike. With our research we hope to provide a thorough investigation into these hot-spots and also provide such information of stolen bike occurrences to the Toronto Police.
\pagebreak

### Dataset Description

**Table 1: Dataset Observations, Data types, and Descriptions**
```{r}
Types = c(class(origin$X_id), class(origin$event_unique_id), class(origin$Primary_Offence), class(origin$Occurrence_Date), class(origin$Occurrence_Year), class(origin$Occurrence_Month), class(origin$Occurrence_DayOfWeek), class(origin$Occurrence_DayOfMonth), class(origin$Occurrence_DayOfYear), class(origin$Occurrence_Hour), class(origin$Report_Date), class(origin$Report_Year), class(origin$Report_Month), class(origin$Report_DayOfWeek), class(origin$Report_DayOfMonth), class(origin$Report_DayOfYear), class(origin$Report_Hour), class(origin$Division), class(origin$City), class(origin$Hood_ID), class(origin$NeighbourhoodName), class(origin$Location_Type), class(origin$Premises_Type), class(origin$Bike_Make), class(origin$Bike_Model), class(origin$Bike_Type), class(origin$Bike_Speed), class(origin$Bike_Colour), class(origin$Cost_of_Bike), class(origin$Status), class(origin$geometry))
Variable = c(colnames(origin))

Description = c("unique entry id order", "unique event id unsorted", "type of crime committed", "date of crime committed", "year of crime committed", "month of crime committed", "days of week crime (Mon-Sun)", "date of month crime (1-31)", "day of year crime (1-365)", "hour of day crime (1-24)", "incident reported to authorities", "year of incident reported", "month of incident reported", "day of week incident (Mon-Sun)", "day of month incident (1-31)", "day of year incident (1-365)", "hour of day incident", "division of location", "city name in Toronto", "hood id for neighborhoods (out of 158)", "neighborhood name in Toronto", "broad crime location", "description of bike theft location", "bike brand in theft", "bike model in theft", "type of bike stolen", "bike color in theft", "bike speed in theft", "bike cost in theft", "current bike status", "precise crime location")

# Combine vectors into a data frame
df <- data.frame(Variable = Variable, Types = Types, Description = Description)

# Convert data frame to a knitr table
knit_table <- knitr::kable(df, align = rep("l", ncol(df)))

# Print the knitr table
print(knit_table)

```

\pagebreak
As with all the data, let us do a preliminary safety removal of any data that has NA entries.
In addition, let us print out a summary of crimes by year to see if there are any outliers.\
\
**Figure 1: Total Number of Bike Thefts Each Year**
```{r, echo=FALSE}
#omit all the entries that has NA inputs, they won't be helpful to our data
data <- na.omit(origin)
summary <- table(data$Occurrence_Year)
print(summary)
```

We can see that there are some outliers from 2009-2013. In addition, the 2022 data is not complete. Let us filter them out and obtain a complete data, the one we will be using for our report below.\
\
**Figure 2: Data After Filtering Incomplete Years**
```{r}
data = data %>% filter(Occurrence_Year >= 2014) %>%
  filter(Occurrence_Year < 2022)
summary_table = data %>% count(Occurrence_Year) %>% 
  rename(Year = Occurrence_Year, Theft_Count = n)
print(summary_table)
```
\newpage
For our first observation, let us use grouping, summarizing to create a simple plot\
\
**Figure 3: Average Cost of Stolen Bikes by Occurrence Year**
```{r}
# Calculate average cost of bike by year
avg_cost_by_year <- data %>%
  group_by(Occurrence_Year) %>%
  summarize(avg_cost = mean(Cost_of_Bike))

# Create plot of average cost of bike by year
ggplot(avg_cost_by_year, aes(x = Occurrence_Year, y = avg_cost)) +
  geom_line(color = "blue") +
  geom_point(color = "blue") +
  labs(x = "Occurrence Year", y = "Average Cost of Bike")
  #ggtitle("Average Cost of Stolen Bikes by Occurrence Year")
```
From the graph, we can observe that there was a upward trend of the bike pricing until the 2020.
This could suggest a decrease in bike quality stolen since the pandemic started.
\newpage
For our next observation, let us utilize the hour variable given to determine the high traffic time for bike thefts.\
\
**Figure 4: Number of Thefts During each Hour**
```{r}
ggplot(data = data, aes(x = Occurrence_Hour)) +
  geom_histogram(binwidth = 1, color = "black", fill = "lightblue") +
  labs(x = "Occurrence Hour", y = "Number of Thefts") 
  #ggtitle("Number of Thefts During each Hour")
```
Observing this histogram, we can see that after midnight, there is a significant decrease in thefts.
The theft occurrences spikes again after 7am before peaking at 6pm. This observation make sense as most citizens secure their bikes during nighttime, while incidents are more likely to occur during high traffic times in the morning and evening.
\pagebreak
For our next observation, let us create a shaded histogram to see if we can observe anything related to day of the year and bike thefts
For this graph, we have decided to take the 2019-2021 as it is recent and having more year would overcrowd the graph.\
\
**Figure 5: Bike Thefts Count in 2019-2021 by day of year**
```{r, message=F}

data2 = data %>% filter(Occurrence_Year %in% c(2019,2020,2021))

ggplot(data2, aes( x=Report_DayOfYear)) +
  geom_histogram(aes(fill=factor(Occurrence_Year)),alpha=0.5)+
  labs(fill="Occurrence_Year") + 
  labs(x = "Day of Year", y = "Counts")
  #ggtitle("Bike Thefts in the first half of recent years")
```
We can deduce that overall, bike thefts count start to spike starting day 100, which is roughly starting April. It peaks during day 200 or so, which is roughly the midst of summer. This observation makes sense as more people are likely to take out their bikes and bike during the warmer season compared to the winter.
In addition, we see a decrease in bike thefts after 2019. This could be the reason to our downward trend in Figure 3, where the lower average prices is resulted by this decrease in theft count.

\pagebreak
It is also interesting for us to see what type of bike are the Toronto population riding. Let us create a summary table to find out what is the most popular bike colour and make in 2021.\
\
**Figure 6: Bike Make and Colour of stolen bikes in Toronto 2021**
```{r, warning=F, message=F}

data3 = data %>%
  filter(Occurrence_Year == c(2021)) %>%
  group_by(Occurrence_Year, Bike_Make, Bike_Colour) %>%
  summarise(total = sum(n=n())) %>%
  arrange(desc(total))
as.data.frame(data3) %>% head(10)
```

From the above table, we can notice that the most frequent type of bike stolen in 2021 was a black model OT.
We can also observe that, in general, Toronto prefer black bikes above the rest.\
\pagebreak
We can identify whether a hood is in the East, West, North, Central or Downtown by looking at the HOOD_ID
Let us create a graph of percentages.\
\
**Figure 7: Neighborhood Group Counts**
```{r, warning=F, message=F}

new_table <- table(data$NeighbourhoodName)
# create data frame with neighborhood names and counts
new_df <- data.frame(nh = names(new_table), count = as.vector(new_table), hood_id = unique(data$Hood_ID[match(names(new_table), data$NeighbourhoodName)]))

new_df$hood_id <- as.numeric(new_df$hood_id)

new_df <- new_df %>% mutate(nh_groups = case_when(new_df$hood_id >= 112 ~ 'East',
                                                  (new_df$hood_id<112 & new_df$hood_id>=84) ~ 'Central',
                                                  (new_df$hood_id<84 & new_df$hood_id>=56)~'Downtown',
                                                  (new_df$hood_id<56 & new_df$hood_id>=28)~'North',
                                                  TRUE~'West'))

grouped_data <- new_df %>% 
  group_by(nh_groups) %>% 
  summarize(count = sum(count)) %>%
  mutate(percentage = percent(count / sum(count)))

# create a pie chart
ggplot(grouped_data, aes(x = "", y = count, fill = nh_groups)) +
  geom_col(width = 1) +
  coord_polar(theta = "y") +
  labs(fill = "Neighborhood Groups") +
  ggtitle("Neighborhood Group Counts") +
  geom_text(aes(label = percentage), position = position_stack(vjust = 0.5)) +
  scale_y_continuous(labels = percent_format()) +
  theme_void() +
  theme(text = element_text(size = 12))

```
\
As we can see, most bike thefts occurs at Downtown. We expected that result since downtown is the most busy place in Toronto.
\pagebreak

Let's map out the occurrences of such bike thefts onto a scatter plot to visualize the span of the thefts across Toronto.\
\
**Figure 8: Bike Stolen Locations in Toronto**
```{r}

# Extracting longitude and latitude using regular expressions
data <- data %>%
  mutate(longitude = as.numeric(sub(".*\\((-?\\d+\\.\\d+),.*", "\\1", geometry)),
         latitude = as.numeric(sub(".*,(\\s?-?\\d+\\.\\d+)\\)}", "\\1", geometry))) %>%
  filter(longitude != 0 & latitude != 0 &
         longitude > -79.7 & longitude < -79.1) %>%
  mutate(cost_lost = case_when(Cost_of_Bike>=600~"high",
                               (Cost_of_Bike<600 & Cost_of_Bike>=400)~"mid",
                               TRUE ~"low"))

img <- readPNG("toronto2.png")
# Plot the data
ggplot(data, aes(x = longitude, y = latitude, color = cost_lost)) +
  background_image(img) +
  geom_point(alpha = 0.5) +
  scale_color_manual(values = c("low" = "red", "mid" = "yellow", "high" = "green"),
                     name = "Cost of Bike") +
  ggtitle("Bike Stolen Locations in Toronto") +
  xlab("Longitude") +
  ylab("Latitude")

```
\
Once again, we can see mass overlapping at downtown area.
Also, note that due to the inability to access the google API, the map background is implemented by hand, therefore it was offset by a bit.
\pagebreak
Let's now take a sample of 1000 observations from the dataset and construct a 97% confidence interval for the proportion of bikes stolen on a Monday. Let's also construct a 97% Bootstrap proportion of bikes stolen on a Monday:

```{r}
samp = data %>% sample_n(1000)

prop.test(x = sum(samp$Occurrence_DayOfWeek == "Monday"), n = length(samp$Occurrence_DayOfWeek), conf.level = 0.97)

boot_function = function(){
  
  boot_data = samp  %>% sample_n(nrow(samp), replace = T)
  
  boot_prop = mean(boot_data$Occurrence_DayOfWeek == "Monday")
  
  return(boot_prop)
  
}

quantile(replicate(1000, boot_function()), c(0.1, 0.9))

```

From this, we know that ...
\pagebreak


```{r}
#Linear Regression and Cross Validation part

# Split the data into training and test sets
set.seed(99)
trainIndex <- createDataPartition(summary_table$Theft_Count, p = .8, list = FALSE)
training <- summary_table[trainIndex,]
testing <- summary_table[-trainIndex,]

# Fit a linear regression model to the training data
lm_model <- lm(Theft_Count ~ Year, data = training)

# Print the summary of the model
summary(lm_model)

# Fit the linear regression model using 10-fold cross-validation
ctrl <- trainControl(method = "cv", number = 10)
lmFit <- train(Theft_Count ~ Year, data = training, method = "lm",
               trControl = ctrl)

# Predict values for the training and test sets
training$predicted <- predict(lm_model, newdata = training)
testing$predicted <- predict(lm_model, newdata = testing)

# Plot the results with the line of best fit
ggplot(training, aes(x = Year, y = Theft_Count)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red", alpha=0.1) +
  labs(title = "Bike Theft in Toronto",
       x = "Year of Bike Theft",
       y = "Number of Bikes Stolen") +
  geom_line(aes(x = Year, y = predicted), data = training, color = "blue") +
  geom_line(aes(x = Year, y = predicted), data = testing, color = "green")

```



